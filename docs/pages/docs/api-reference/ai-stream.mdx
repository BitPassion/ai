---
title: AIStream
---

import { OptionTable } from '@/components/table'

# AIStream

## `AIStream(res: Response, customParser: (opts: AIStreamParserOptions) => void, callbacks?: AIStreamCallbacks): ReadableStream` [#aistream]

`AIStream` is a helper function for creating a readable stream for AI responses. This is based on the responses returned by `fetch` and serves as the basis for the [`OpenAIStream`](./openai-stream) and [`AnthropicStream`](./anthropic-stream). It allows you to handle AI response streams in a controlled and customized manner that will work with [`useChat`](./use-chat) and [`useCompletion`](./use-completion).

`AIStream` will throw an error if `res` doesn't have a `2xx` status code. This is to ensure that the stream is only created for successful responses.

## Parameters

### `res: Response`

This is the response object returned by `fetch`. It's used as the source of the readable stream.

### `customParser: (opts: AIStreamParserOptions) => void`

This is a function that is used to parse the events in the stream. It takes an `AIStreamParserOptions` object as a parameter. The function is expected to return nothing (`void`).

### `callbacks?: AIStreamCallbacks`

This is an optional parameter which is an object that contains callback functions for handling the start, completion, and each token of the AI response.

### Types

#### `AIStreamParserOptions`

This is an object that contains the following properties:

<OptionTable
  options={[
    ['data', 'any', 'The data extracted from the event in the stream.'],
    [
      'controller',
      'ReadableStreamDefaultController',
      'The controller of the readable stream.'
    ],
    [
      'counter',
      'number',
      'A counter variable, initialized as 0 and incremented each time the parser function is called.'
    ],
    ['encoder', 'TextEncoder', 'A `TextEncoder` instance.']
  ]}
/>

#### `AIStreamCallbacks`

This is an object that contains the following properties:

<OptionTable
  options={[
    [
      'onStart',
      '() => Promise<void>',
      'An optional function that is called at the start of the stream processing.'
    ],
    [
      'onCompletion',
      '(completion: string) => Promise<void>',
      "An optional function that is called when the stream processing is complete. It's passed the completion as a string."
    ],
    [
      'onToken',
      '(token: string) => Promise<void>',
      "An optional function that is called for each token in the stream. It's passed the token as a string."
    ]
  ]}
/>

## Example: Using `AIStream` to create [`AnthropicStream`](./anthropic-stream)

Here is real example of how to use `AIStream` to create a stream that will work with [`useChat`](./use-chat) and [`useCompletion`](./use-completion). Here's is the implementation for [`AnthropicStream`](./anthropic-stream) which expects a response returned by `fetch`. [`AnthropicStream`](./anthropic-stream) is a specific implementation of `AIStream` for the Anthropic AI platform.

```tsx
import {
  AIStream,
  type AIStreamParserOptions,
  type AIStreamCallbacks
} from 'ai'

// The custom parser for Anthropic responses
function parseAnthropicStream({
  data,
  controller,
  counter,
  encoder
}: AIStreamParserOptions): void {
  try {
    // Parse the JSON data
    const json = JSON.parse(data as string) as {
      completion: string
      stop: string | null
      stop_reason: string | null
      truncated: boolean
      log_id: string
      model: string
      exception: string | null
    }

    const text = json.completion

    // If there are newline characters in the text, skip the first two lines
    if (counter < 2 && (/\n/.exec(text) || []).length) {
      return
    }

    // Encode the text and enqueue it into the stream
    const queue = encoder.encode(`${JSON.stringify(text)}\n`)
    controller.enqueue(queue)

    // Increment the counter
    counter++
  } catch (e) {
    // In case of any errors, signal the error to the stream
    controller.error(e)
  }
}

export function AnthropicStream(
  res: Response,

  cb?: AIStreamCallbacks
): ReadableStream {
  // Create a new AIStream with the Anthropic parser and the provided callbacks
  return AIStream(res, parseAnthropicStream, cb)
}

// Then you can use AnthropicStream like this:
const fetchResponse = await fetch('/api/anthropic-endpoint')
const anthropicStream = AnthropicStream(fetchResponse, {
  onStart: async () => {
    console.log('Stream started')
  },
  onCompletion: async completion => {
    console.log('Stream completed', completion)
  },
  onToken: async token => {
    console.log('Token received', token)
  }
})
// Now you can consume the anthropicStream
```

In the example above, we first define a `parseAnthropicStream` function that handles the specific data structure returned by the Anthropic platform.
We then create an `AnthropicStream` function which uses `AIStream` with the `parseAnthropicStream` parser.
Finally, we fetch a response and pass it to `AnthropicStream` along with some callback functions, and create a readable stream that we can consume as desired.
